<!DOCTYPE html>
<html lang="en-us"><head><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">AI Untwined | ndelor.me</title>
<meta property="og:title" content="AI Untwined | ndelor.me" />
<meta name="twitter:title" content="AI Untwined | ndelor.me" />
<meta itemprop="name" content="AI Untwined | ndelor.me" />
<meta name="application-name" content="AI Untwined | ndelor.me" />
<meta property="og:site_name" content="" />

<meta name="description" content="">
<meta itemprop="description" content="" />
<meta property="og:description" content="" />
<meta name="twitter:description" content="" />

<meta property="og:locale" content="en-us" />
<meta name="language" content="en-us" />

  <link rel="alternate" hreflang="en" href="https://ndelor.me/posts/ai-untwined/" title="" />





    
    
    

    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content=2025-02-12T06:55:09Z />
    <meta property="article:published_time" content=2025-02-12T06:55:09Z />
    <meta property="og:url" content="https://ndelor.me/posts/ai-untwined/" />

    
    <meta property="og:article:author" content="Nicolas Delorme" />
    <meta property="article:author" content="Nicolas Delorme" />
    <meta name="author" content="Nicolas Delorme" />
    
    

    

    <script defer type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "AI Untwined",
        "author": {
        "@type": "Person",
        "name": ""
        },
        "datePublished": "2025-02-12",
        "description": "",
        "wordCount":  1114 ,
        "mainEntityOfPage": "True",
        "dateModified": "2025-02-12",
        "image": {
        "@type": "imageObject",
        "url": ""
        },
        "publisher": {
        "@type": "Organization",
        "name": "ndelor.me"
        }
    }
    </script>


<meta name="generator" content="Hugo 0.123.7">

    
    <meta property="og:title" content="AI Untwined" />
<meta property="og:description" content="Operations There are several fundamental types of AI/ML operations, including:
Embedding â€“ Converts input data into vector representations. Inference â€“ Applies a trained model to make predictions or classifications. Training â€“ Adjusts model parameters based on data to learn patterns. Fine-tuning â€“ Adapts a pre-trained model to a specific task. Preprocessing â€“ Cleans, normalizes, or structures raw data before use. Postprocessing â€“ Refines model outputs for final consumption. Retrieval â€“ Searches and fetches relevant information (e." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ndelor.me/posts/ai-untwined/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-02-12T06:55:09+00:00" />
<meta property="article:modified_time" content="2025-02-12T06:55:09+00:00" />



    
    <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="AI Untwined"/>
<meta name="twitter:description" content="Operations There are several fundamental types of AI/ML operations, including:
Embedding â€“ Converts input data into vector representations. Inference â€“ Applies a trained model to make predictions or classifications. Training â€“ Adjusts model parameters based on data to learn patterns. Fine-tuning â€“ Adapts a pre-trained model to a specific task. Preprocessing â€“ Cleans, normalizes, or structures raw data before use. Postprocessing â€“ Refines model outputs for final consumption. Retrieval â€“ Searches and fetches relevant information (e."/>


    

    <link rel="canonical" href="https://ndelor.me/posts/ai-untwined/">
    <link href="/style.min.e390ba7da26222f4dc42a349955d76dbbe44e5ce2535a43de5a70633a0a9ec3c.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="https://ndelor.me/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
    
</head>
<body data-theme = "" class="notransition">

<script src="/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js" integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="https://ndelor.me/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title></title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/about/">
                        About
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/posts/">
                        Posts
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/projects/">
                        Projects
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/tags/">
                        Tags
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">AI Untwined</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-02-12T06:55:09&#43;00:00" itemprop="datePublished"> Feb 12, 2025 </time>
                </div>
                
            </header>
            
            <div class="page-content">
                <h2 id="operations"><strong>Operations</strong></h2>
<p>There are several fundamental types of AI/ML operations, including:</p>
<ol>
<li><strong>Embedding</strong> â€“ Converts input data into vector representations.</li>
<li><strong>Inference</strong> â€“ Applies a trained model to make predictions or classifications.</li>
<li><strong>Training</strong> â€“ Adjusts model parameters based on data to learn patterns.</li>
<li><strong>Fine-tuning</strong> â€“ Adapts a pre-trained model to a specific task.</li>
<li><strong>Preprocessing</strong> â€“ Cleans, normalizes, or structures raw data before use.</li>
<li><strong>Postprocessing</strong> â€“ Refines model outputs for final consumption.</li>
<li><strong>Retrieval</strong> â€“ Searches and fetches relevant information (e.g., RAG).</li>
<li><strong>Generation</strong> â€“ Produces new content (e.g., text, images, code).</li>
<li><strong>Optimization</strong> â€“ Refines a system or model for efficiency or accuracy.</li>
<li><strong>Distillation</strong> â€“ Transfers knowledge from a large model (teacher) to a smaller one (student) for efficiency.</li>
<li><strong>Quantization</strong> â€“ Reduces model precision (e.g., FP32 â†’ INT8) for faster execution.</li>
</ol>
<h2 id="model-variants--flavors"><strong>Model Variants &amp; Flavors</strong></h2>
<p>AI models differ based on architecture, use case, and efficiency:</p>
<ul>
<li><strong>Transformers</strong> â€“ Large, general-purpose (e.g., GPT, LLaMA, Mistral).</li>
<li><strong>Sentence Transformers</strong> â€“ Optimized for embeddings (e.g., SBERT).</li>
<li><strong>Diffusion Models</strong> â€“ Used for image generation (e.g., Stable Diffusion).</li>
<li><strong>RNNs/LSTMs</strong> â€“ Sequential data modeling (less common now).</li>
<li><strong>Small-scale Models</strong> â€“ Lighter models for edge devices (e.g., DistilBERT, Gemma).</li>
<li><strong>On-Device ML</strong> â€“ TinyML, MobileNet, Whisper small versions.</li>
</ul>
<h2 id="frameworks--libraries"><strong>Frameworks &amp; Libraries</strong></h2>
<ul>
<li><strong>PyTorch</strong> (open-source) â€“ Most flexible, widely used for research and deployment.</li>
<li><strong>TensorFlow</strong> (open-source) â€“ Industry adoption, supports mobile (TensorFlow Lite).</li>
<li><strong>JAX</strong> (open-source) â€“ Optimized for high-performance computing.</li>
<li><strong>ONNX</strong> (open-source) â€“ Standard format for cross-framework model execution.</li>
<li><strong>Jupyter Notebooks</strong> -</li>
</ul>
<h2 id="model-execution--optimization"><strong>Model Execution &amp; Optimization</strong></h2>
<ul>
<li><strong>ONNX Runtime</strong> â€“ Runs ONNX models efficiently on CPU/GPU.</li>
<li><strong>TorchScript</strong> â€“ Converts PyTorch models to optimized bytecode.</li>
<li><strong>TensorRT</strong> (proprietary) â€“ NVIDIAâ€™s high-performance inference engine.</li>
<li><strong>GGUF (GPT-based)</strong> â€“ Optimized quantized formats for local LLMs.</li>
</ul>
<h2 id="platforms-for-running-models-locally"><strong>Platforms for Running Models Locally</strong></h2>
<ul>
<li><strong>Hugging Face Transformers</strong> (open-source) â€“ Load/run pre-trained models easily.</li>
<li><strong>Ollama</strong> (open-source) â€“ Simplifies running local LLMs.</li>
<li><strong>LM Studio</strong> (open-source) â€“ GUI for running LLMs locally.</li>
<li><strong>Whisper.cpp/Llama.cpp</strong> (open-source) â€“ Optimized for CPU-based execution.</li>
<li><strong>FastText</strong> (open-source) â€“ Lightweight text classification/embedding.</li>
</ul>
<h2 id="the-two-stages"><strong>The &ldquo;Two Stages&rdquo;</strong></h2>
<p>Machine learning workflows typically consist of two major phases:</p>
<ol>
<li>
<p><strong>Experimental Stage (Research &amp; Prototyping)</strong></p>
<ul>
<li>This is where models are built, tested, and refined.</li>
<li>Often involves:
<ul>
<li><strong>Trying different architectures</strong> (CNNs, RNNs, Transformers, etc.).</li>
<li><strong>Hyperparameter tuning</strong>.</li>
<li><strong>Working with datasets interactively</strong>.</li>
</ul>
</li>
<li>Traditionally done in Python using <strong>PyTorch, TensorFlow, Jupyter Notebooks</strong>, etc.</li>
<li>Optimized for <strong>flexibility</strong> rather than performance.</li>
</ul>
</li>
<li>
<p><strong>Deployment Stage (Production)</strong></p>
<ul>
<li>Once a model is finalized, it needs to be deployed for inference.</li>
<li>Requirements shift towards:
<ul>
<li><strong>Efficiency</strong> (low latency, high throughput).</li>
<li><strong>Scalability</strong> (runs efficiently on CPUs/GPUs in production).</li>
</ul>
</li>
<li>Typically, models are &ldquo;rewritten&rdquo; in <strong>C++ (mlpack, dlib)</strong> or <strong>optimized with TensorFlow Serving, ONNX Runtime, or TensorRT</strong> for performance.</li>
</ul>
</li>
</ol>
<h2 id="how-models-can-be-rewritten"><strong>How Models Can Be &ldquo;Rewritten&rdquo;</strong></h2>
<p>The term <strong>&ldquo;rewriting&rdquo; a model</strong> usually refers to optimizing or converting it from one framework to another for production use. This happens in several ways:</p>
<h3 id="a-manual-rewriting-traditional"><strong>a. Manual Rewriting (Traditional)</strong></h3>
<ul>
<li>Data scientists prototype models in <strong>Python (PyTorch, TensorFlow)</strong>.</li>
<li>Engineers rewrite them in <strong>C++, Rust, or optimized C libraries</strong> for efficiency.</li>
<li>Example:
<ul>
<li>A TensorFlow model trained in Python is rewritten using <strong>C++ (dlib, mlpack)</strong> for deployment.</li>
</ul>
</li>
</ul>
<h3 id="b-model-conversion-modern-approach"><strong>b. Model Conversion (Modern Approach)</strong></h3>
<ul>
<li>Instead of manually rewriting models, conversion tools allow them to be transformed:
<ul>
<li><strong>ONNX</strong>: Converts models from PyTorch/TensorFlow to ONNX, which can run efficiently with <strong>ONNX Runtime</strong>.</li>
<li><strong>TorchScript</strong>: Converts PyTorch models into deployable binaries.</li>
<li><strong>TensorRT</strong>: Optimizes TensorFlow/PyTorch models for NVIDIA GPUs.</li>
<li><strong>GGUF</strong> (Llama.cpp format): Optimizes LLMs for local execution.</li>
</ul>
</li>
</ul>
<h1 id="learning-plan-mastering-embedding-deployment--search-in-go"><strong>Learning Plan: Mastering Embedding Deployment &amp; Search in Go</strong></h1>
<p>ðŸ”¹ <strong>Goal:</strong> Develop <strong>expertise in running, optimizing, and deploying various embedding models locally</strong> using Go.<br>
ðŸ”¹ <strong>Scope:</strong> Focus on <strong>deployment, inference optimization, and retrieval</strong>â€”<strong>not model training</strong>.</p>
<hr>
<h2 id="-step-1-api-based-embeddings-with-local-tokenization"><strong>ðŸŸ¢ Step 1: API-Based Embeddings with Local Tokenization</strong></h2>
<p>âœ… <strong>Goal:</strong> Learn embedding fundamentals by using a 3rd-party API (e.g., <strong>VoyageAI, OpenAI</strong>) while <strong>handling tokenization locally</strong>.</p>
<p>ðŸ”¹ <strong>Key Concepts:</strong></p>
<ul>
<li>How <strong>embeddings</strong> work &amp; what they represent.</li>
<li><strong>Tokenization</strong> (splitting text into subwords) to control request size.</li>
<li>Making <strong>efficient API calls</strong> in Go.</li>
</ul>
<p>ðŸ”¹ <strong>Tech Stack:</strong></p>
<ul>
<li><strong>Embedding API:</strong> <a href="https://docs.voyageai.com/">VoyageAI</a> or OpenAI</li>
<li><strong>Tokenizer:</strong> <a href="https://github.com/sugarme/tokenizer"><code>github.com/sugarme/tokenizer</code></a></li>
</ul>
<p>ðŸ”¹ <strong>Tasks:</strong></p>
<ol>
<li>Install <strong>sugarme/tokenizer</strong> and test tokenization.</li>
<li>Make an API call to <strong>VoyageAI/OpenAI</strong> for embeddings.</li>
<li><strong>Store embeddings</strong> in-memory or in a JSON file.</li>
<li>Compute <strong>cosine similarity</strong> manually for a simple search function.</li>
</ol>
<p>âœ… <strong>Outcome:</strong> Understand embeddings, API usage, and tokenization in Go.</p>
<hr>
<h2 id="-step-2-replace-api-calls-with-local-ollama-model"><strong>ðŸŸ¡ Step 2: Replace API Calls with Local Ollama Model</strong></h2>
<p>âœ… <strong>Goal:</strong> <strong>Run embeddings locally</strong> using <strong>Ollama</strong>, removing external API dependencies.</p>
<p>ðŸ”¹ <strong>Key Concepts:</strong></p>
<ul>
<li>Running <strong>Ollama models</strong> on a local machine.</li>
<li>Comparing <strong>local inference speed vs. API latency</strong>.</li>
<li><strong>Vector storage</strong> for search.</li>
</ul>
<p>ðŸ”¹ <strong>Tech Stack:</strong></p>
<ul>
<li><strong>Embeddings:</strong> <a href="https://ollama.ai/">Ollama</a> (<code>ollama run mxbai-embed-large</code>)</li>
<li><strong>Vector Database:</strong> FAISS (<code>github.com/DataIntelligenceCrew/go-faiss</code>) or Qdrant (<code>qdrant-client-go</code>)</li>
</ul>
<p>ðŸ”¹ <strong>Tasks:</strong></p>
<ol>
<li>Install and <strong>run Ollama embedding model</strong> (<code>mxbai-embed-large</code>).</li>
<li>Generate <strong>embeddings locally</strong> in Go via the <strong>Ollama API</strong>.</li>
<li>Store embeddings in <strong>FAISS or Qdrant</strong> for fast retrieval.</li>
<li>Implement <strong>similarity search (cosine distance, k-NN)</strong>.</li>
</ol>
<p>âœ… <strong>Outcome:</strong> Hands-on experience with <strong>local inference and vector DB integration</strong>.</p>
<hr>
<h2 id="-step-3-optimize-embedding-model-execution"><strong>ðŸŸ  Step 3: Optimize Embedding Model Execution</strong></h2>
<p>âœ… <strong>Goal:</strong> <strong>Experiment with different ways to optimize inference performance</strong>.</p>
<p>ðŸ”¹ <strong>Key Concepts:</strong></p>
<ul>
<li><strong>Quantization</strong> (reducing model size for speed).</li>
<li><strong>Multi-threading for parallel inference</strong>.</li>
<li><strong>Benchmarking different models</strong>.</li>
</ul>
<p>ðŸ”¹ <strong>Tech Stack:</strong></p>
<ul>
<li><strong>Optimized Ollama models</strong> (quantized <code>.gguf</code> versions).</li>
<li><strong>Profiling tools</strong> (<code>pprof</code>, Go Benchmarking).</li>
<li><strong>Multi-threading</strong> in Go.</li>
</ul>
<p>ðŸ”¹ <strong>Tasks:</strong></p>
<ol>
<li>Run <strong>different Ollama models</strong> (<code>nomic-embed-text</code>, <code>mxbai-embed-large</code>).</li>
<li>Compare speed &amp; accuracy of <strong>quantized vs. non-quantized models</strong>.</li>
<li>Benchmark <strong>batch inference</strong> performance.</li>
<li>Experiment with <strong>parallel embedding generation</strong>.</li>
</ol>
<p>âœ… <strong>Outcome:</strong> Ability to <strong>fine-tune performance settings for embedding models</strong>.</p>
<hr>
<h2 id="-step-4-use-onnx-runtime-for-faster-local-inference"><strong>ðŸ”´ Step 4: Use ONNX Runtime for Faster Local Inference</strong></h2>
<p>âœ… <strong>Goal:</strong> Run an <strong>ONNX-optimized embedding model</strong> using Go, bypassing Python overhead.</p>
<p>ðŸ”¹ <strong>Key Concepts:</strong></p>
<ul>
<li><strong>ONNX format</strong> for running models across platforms.</li>
<li><strong>Optimized inference on CPU/GPU</strong>.</li>
<li>Running ONNX models <strong>without Python</strong>.</li>
</ul>
<p>ðŸ”¹ <strong>Tech Stack:</strong></p>
<ul>
<li><strong>ONNX Runtime:</strong> <a href="https://github.com/yalue/onnxruntime_go"><code>github.com/yalue/onnxruntime_go</code></a>.</li>
<li><strong>ONNX Models:</strong> Download from Hugging Face (<code>all-MiniLM-L6-v2.onnx</code>).</li>
</ul>
<p>ðŸ”¹ <strong>Tasks:</strong></p>
<ol>
<li>Install and <strong>load an ONNX model in Go</strong>.</li>
<li>Generate embeddings using <strong>onnxruntime_go</strong>.</li>
<li>Compare performance vs. <strong>Ollama embeddings</strong>.</li>
<li>Integrate ONNX-based embeddings into <strong>FAISS or Qdrant</strong>.</li>
</ol>
<p>âœ… <strong>Outcome:</strong> Expertise in running <strong>optimized ONNX models</strong> for embedding generation.</p>
<hr>
<h2 id="-summary-building-a-go-based-embedding-powerhouse"><strong>ðŸ“ˆ Summary: Building a Go-Based Embedding Powerhouse</strong></h2>
<table>
<thead>
<tr>
<th><strong>Step</strong></th>
<th><strong>Focus</strong></th>
<th><strong>Tech Used</strong></th>
<th><strong>Outcome</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1</strong></td>
<td>API-based embeddings &amp; tokenization</td>
<td>VoyageAI/OpenAI, <code>sugarme/tokenizer</code></td>
<td>Learn embeddings, tokenization, API integration</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td>Local embedding inference</td>
<td>Ollama, FAISS/Qdrant</td>
<td>Run embeddings locally, store vectors, implement search</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td>Optimization &amp; performance tuning</td>
<td>Ollama, Quantized Models, Go Benchmarking</td>
<td>Reduce inference latency, experiment with model settings</td>
</tr>
<tr>
<td><strong>4</strong></td>
<td>ONNX for high-performance inference</td>
<td>ONNX Runtime (<code>onnxruntime_go</code>)</td>
<td>Deploy highly efficient embedding models locally</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="enhancements--optional-next-steps"><strong>Enhancements &amp; Optional Next Steps</strong></h2>
<p>ðŸš€ <strong>Expand skills further with:</strong></p>
<ul>
<li><strong>Use embeddings in a real-world app</strong> (e.g., a CLI for searching a Git repo).</li>
<li><strong>Deploy as a web service</strong> (Go + Gin/Fiber).</li>
<li><strong>Experiment with different vector DBs</strong> (Weaviate, Pinecone).</li>
<li><strong>Explore quantization &amp; model compression</strong> further.</li>
</ul>
<hr>
<h2 id="final-thoughts"><strong>Final Thoughts</strong></h2>
<p>âœ… <strong>This learning plan is focused on real-world skills</strong>â€”deploying, running, and optimizing <strong>embedding models</strong> in Go.<br>
âœ… <strong>Enhancements allow deeper performance tuning</strong>.<br>
âœ… <strong>No unnecessary detours into training models</strong>â€”just practical embedding-based search.</p>
<p>Would you like <strong>example code scaffolding</strong> for any step? ðŸš€</p>

            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;
    <img height="48" style="padding-bottom: 16px;" class="author-avatar" src="/images/logo.png" alt="Nicolas Delorme">

    <div class="footer_social-icons">
<a href="https://github.com/cyber-nic" target="_blank" rel="noopener noreferrer me"
    title="GitHub">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
</a>
<a href="https://www.linkedin.com/in/nicolas-delorme-588ba619/" target="_blank" rel="noopener noreferrer me"
    title="LinkedIn">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
</a>
</div>
    <small class="footer_copyright">
        Â© 2026 Nicolas Delorme.
        
    </small>
</footer>







    
    <script src="https://ndelor.me/js/main.min.4ee188e1744c19816e95a540b2650ed9f033ea0371e74eac8e717355cfca8741.js" integrity="sha256-TuGI4XRMGYFulaVAsmUO2fAz6gNx506sjnFzVc/Kh0E="></script>

    

</body>
</html>
