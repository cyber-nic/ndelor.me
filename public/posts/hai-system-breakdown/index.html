<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta
    name="description"
    content=""
  />
  
    
      <title>History AI - Part II: System Design | Context Chronicles</title>
    
  
  <link rel="stylesheet" href="/css/reset.css"/>
  <link rel="stylesheet" href="/css/font.css"/>
  <link rel="stylesheet" href="/css/smigle.css"/>
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
</head>

  <body>
    <div id="root">
      <header>
  <div id="brand">
    <a class="icon-link" href="http://contextchronicles.com/">
      <img
        class="icon"
        src="/images/logo.png"
      />
    </a>
    <div class="text">
      <a href="http://contextchronicles.com/"><h1>Context Chronicles</h1></a>
      <h3>Stuff.</h3>
    </div>
  </div>
  <nav>
    
      
        
        <a href="/"><b>Home</b></a>
      
         | 
        <a href="/about/"><b>About</b></a>
      
         | 
        <a href="/posts/"><b>Posts</b></a>
      
         | 
        <a href="/categories/"><b>Categories</b></a>
      
         | 
        <a href="/tags/"><b>Tags</b></a>
      
    
  </nav>
  <hr />
</header>

      <div id="content">
        
  <main>
    <article>
      <h1>History AI - Part II: System Design</h1>
      <div class="post-meta">
  <strong>
    <span>Posted on</span>
    <time>2023-07-10</time>
    
    
  </strong>
  <span> • 574 words</span>
  <span> • 3 minute read</span>
  
    <div>
      Last updated on
      <time>2023-11-02</time>
    </div>
  
  
    <div>
      <span>Tags:</span>
      
        <a href="/tags/history-ai">history ai</a>, 
        <a href="/tags/system-design">system-design</a>
    </div>
  
</div>

      <div><h1 id="assumptions--constraints">Assumptions / Constraints</h1>
<ol>
<li>We will operate on a dataset of ~2,000,000 jpeg images / ~500GB</li>
<li>The initial budget is $1000. It is expected that this will increase, but the goal is to re-evaluate the budget prior to spending.</li>
<li>We will operate using the Google Cloud Platform (GCP) but might explore other cloud offerings when performance or cost become a concern</li>
</ol>
<h1 id="system-design">System Design</h1>
<p><img src="/images/hai-system-breakdown.svg" alt="breakdown"></p>
<h2 id="scraping">Scraping</h2>
<p>I&rsquo;ve implemented scrapers using various languages including PowerShell, Node.js, Python, and Go. This scraper will also be implemented using Go. At a very high level, the scraping service outputs jpeg images in a folder structure specific to the site being scraped.</p>
<p><strong>Input</strong>: url string</p>
<p><strong>Output</strong>: image files on disk or in bucket</p>
<h2 id="image-preprocessing">Image PreProcessing</h2>
<p>One of the challenges faced is that all the images scraped contain a repetitive watermark. To enhance the quality of subsequent text extraction (OCR), the primary objective is to remove the watermark from these images. By doing so, I aim to obtain clearer and more accurate results.</p>
<p><strong>Update (09/10/23)</strong>: After some analysis I am of the opinion that the work required to remove the watermark or the processing cloud costs would not provide the necessary ROI to justify the effort and exepense. Instead, tests have demonstrated that the OCR process does detect the watermark and as a result it can be filtered out prior to NLP processing.</p>
<p><strong>Update (09/10/23)</strong>: Deeper analysis of the upcoming OCR costs (<a href="https://cloud.google.com/document-ai/pricing#:~:text=%241.50%20per%201%2C000%20pages">$1.50/1000 pages</a>) have led me to the conclusion that cost-saving measures are required. A possible solution is the aggregation of several images into a single &ldquo;page&rdquo;.</p>
<p><strong>Update (2/11/23)</strong>: Final conclusion, the idea of combining images into a single page is pointless has GCP&rsquo;s Document AI OCR documentation states that it will auto-detect, and bill accordingly, for multiple pages in a single image. Since the expected cost of OCR&rsquo;ing this many images is ~$5000USD we&rsquo;ve applied for a Google Research grant to cover the costs. Waiting on a response.</p>
<p><strong>Input</strong>: Image (ie. location of)</p>
<p><strong>Output</strong>: New enhanced image stored in bucket</p>
<h2 id="ocr-and-text-extraction">OCR and Text Extraction</h2>
<p>We strive to perform Optical Character Recognition (OCR) and extract text from a diverse range of sources, including handwritten and typed documents. It&rsquo;s important to note that many documents may also contain additional layers of handwritten text, adding complexity to the extraction process.</p>
<p><strong>Input</strong>: Image (ie. location of)</p>
<p><strong>Output</strong>: Text or JSON</p>
<h2 id="nlp-and-ner">NLP and NER</h2>
<p>Using Natural Language Processing (NLP), the objective is to perform Named Entity Recognition (NER). This involves identifying and categorizing named entities such as people, organizations, locations, and dates within the extracted text. By leveraging NLP techniques, we can gain valuable insights from the recognized entities.</p>
<p>Part of this step will be producing a weighted score for each entity relationship. This would potentially allow us to visually identify the most important entities and relationships using a tool like <a href="https://gephi.org/">Gephi</a>.</p>
<p><strong>Input</strong>: Text</p>
<p><strong>Output</strong>: JSON</p>
<h2 id="llm">LLM</h2>
<p>The final step is to leverage the extracted entities and relationships to produce a Large Language Models (LLM). It will be interesting to see if the model is capable of identifying patterns and relationships that are not immediately obvious to the human eye. I&rsquo;m currently considering multiple options for this step, including GPT-4, <a href="https://github.com/h2oai/h2o-llmstudio">H2O LLM Studio</a>, along with other more customized solutions (as an opportunity to learn more about LLM fundamentals).</p>
<p><strong>Input</strong>: TBD</p>
<p><strong>Output</strong>: TBD</p>
<h1 id="inputs--outputs">Inputs / Outputs</h1>
<p>This diagram illustrates the potential flow of data from one service to the next.</p>
<p><img src="/images/hai-system-breakdown-i_o.svg" alt="io"></p>
<p>Inputs in blue and Outputs in red.</p>
</div>
    </article>
  </main>

      </div>
      <footer>
  <hr />
  
    <p id="social">
      Find me around the web:
      <br />
      
        
        <a href="https://github.com/cyber-nic">GitHub</a>
      
         | 
        <a href="https://www.linkedin.com/in/nicolas-delorme-588ba619/">LinkedIn</a>
      
    </p>
  
  <p class="copyright">
    Copyright © 2024
    <a href="http://contextchronicles.com/"><strong>Nicolas Delorme</strong></a>.
    This work is licensed under the
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> license.
  </p>
  <p class="builtWith">
    Built with
    <a href="http://www.gohugo.io/">Hugo</a>,
    using the theme
    <a href="https://gitlab.com/ian-s-mcb/smigle-hugo-theme">smigle</a>,
    which was influenced by the theme
    <a href="https://github.com/sumnerevans/smol">smol</a>.
  </p>
</footer>

    </div>
  </body>
</html>
